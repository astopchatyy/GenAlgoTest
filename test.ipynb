{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astopchatyy/GenAlgoTest/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07a828fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07a828fc",
        "outputId": "b3339143-3330-4f61-d7a0-b0b7e59fe311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Number of workers: 12\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, List, Type, Iterator\n",
        "from tqdm import tqdm\n",
        "from abc import ABC, abstractmethod\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "import os\n",
        "num_workers = os.cpu_count()\n",
        "print(\"Number of workers:\", num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87f4ddd8",
      "metadata": {
        "id": "87f4ddd8"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class Metric(ABC):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def eval(self, predicted_values: torch.Tensor, true_values: torch.Tensor) -> float:\n",
        "        return 0.0\n",
        "\n",
        "    @abstractmethod\n",
        "    def aggregate(self, values: List) -> float:\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "class Accuracy(Metric):\n",
        "    def eval(self, predicted_values: Tensor, true_values: Tensor) -> float:\n",
        "        _, predicted = torch.max(predicted_values, 1)\n",
        "        return (predicted == true_values).float().mean().item()\n",
        "\n",
        "    def aggregate(self, values: List) -> float:\n",
        "        return sum(values) / len(values)\n",
        "\n",
        "class MSE(Metric):\n",
        "    def eval(self, predicted_values: Tensor, true_values: Tensor) -> float:\n",
        "        return torch.mean((predicted_values - true_values) ** 2).item()\n",
        "\n",
        "    def aggregate(self, values: List) -> float:\n",
        "        return sum(values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b921ed51",
      "metadata": {
        "id": "b921ed51"
      },
      "outputs": [],
      "source": [
        "class GeneticTrainer:\n",
        "    def __init__(self,\n",
        "                 genetic_population_size: int,\n",
        "                 superviser_population_size: int,\n",
        "                 model_class: Type[nn.Module],\n",
        "                 optimizer_class: Type[optim.Optimizer],\n",
        "                 criterion: nn.modules.loss._Loss,\n",
        "                 metric: Metric,\n",
        "                 model_params: Dict={},\n",
        "                 optimizer_params: Dict={}) -> None:\n",
        "\n",
        "        self._model_class = model_class\n",
        "        self._optimizer_class = optimizer_class\n",
        "        self._genetic_population_size = genetic_population_size\n",
        "        self._superviser_population_size = superviser_population_size\n",
        "        self._total_population_size = self._superviser_population_size + self._genetic_population_size\n",
        "        self._metric = metric\n",
        "        self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self._model_params = model_params\n",
        "        self._optimizer_params = optimizer_params\n",
        "\n",
        "        self._population = [self._model_class(**self._model_params).to(device) for _ in range(self._total_population_size)]\n",
        "        self._criterion = criterion\n",
        "        self._optimizers = [self._optimizer_class(self._population[i].parameters(), **self._optimizer_params) for i in range(self._total_population_size)]\n",
        "\n",
        "        self._training_history = None\n",
        "\n",
        "    def train(self,\n",
        "              cycles: int,\n",
        "              train_dataloader: DataLoader,\n",
        "              test_dataloader: DataLoader,\n",
        "              validation_dataloader: DataLoader|None=None,\n",
        "              survivor_fraction: float = 0.5,\n",
        "              mutation_chance: float = 0.1,\n",
        "              epoches_per_cycle=1,\n",
        "              last_cycle_evolution=True,\n",
        "              verbose=2) -> Dict:\n",
        "\n",
        "        if not validation_dataloader:\n",
        "            validation_dataloader = train_dataloader\n",
        "\n",
        "        self._training_history = {\n",
        "            \"crossover_history\": [[] for _ in range(self._genetic_population_size + self._superviser_population_size)],\n",
        "            \"train_losses\": [[] for _ in range(self._genetic_population_size + self._superviser_population_size)],\n",
        "            \"test_metric\": [[] for _ in range(self._genetic_population_size + self._superviser_population_size)],\n",
        "            \"val_metric\": [[] for _ in range(self._genetic_population_size + self._superviser_population_size)]\n",
        "        }\n",
        "        if verbose == 2:\n",
        "            total_len = cycles * (self._total_population_size) * epoches_per_cycle * (len(train_dataloader) + len(validation_dataloader) + len(test_dataloader))\n",
        "        elif verbose == 1:\n",
        "            total_len = cycles * (self._total_population_size) * epoches_per_cycle\n",
        "        else:\n",
        "            total_len = cycles\n",
        "        with tqdm(total=total_len, leave=False) if verbose > 0 else None as pbar:\n",
        "            for cycle in range(cycles):\n",
        "                if verbose not in [1,2]:\n",
        "                    pbar.set_description(f\"Cycle: {cycle+1}/{cycles}\")\n",
        "                    pbar.update(1)\n",
        "                fitness_scores = []\n",
        "                for i in range(self._total_population_size):\n",
        "                    fitness_list = []\n",
        "                    test_fitness_list = []\n",
        "                    train_losses_list = []\n",
        "\n",
        "                    fitness = 0\n",
        "\n",
        "                    for epoch in range(epoches_per_cycle):\n",
        "                        message = f\"Cycle: {cycle+1}/{cycles}, entity: {i+1}/{self._total_population_size}, epoch:{epoch+1}/{epoches_per_cycle}\"\n",
        "                        if verbose == 2:\n",
        "                            progr_bar = pbar\n",
        "                        else:\n",
        "                            progr_bar = None\n",
        "                            if verbose == 1:\n",
        "                                pbar.set_description(message)\n",
        "                                pbar.update(1)\n",
        "                        losses = self._train_one_model_one_epoch(self._population[i],\n",
        "                                                                self._optimizers[i],\n",
        "                                                                self._criterion,\n",
        "                                                                train_dataloader,\n",
        "                                                                progr_bar,\n",
        "                                                                f\"{message}, training: \")\n",
        "                        train_losses_list.append(losses)\n",
        "\n",
        "                        fitness = self._evaluate_model(self._population[i], validation_dataloader, progr_bar, f\"{message}, evaluating validation: \")\n",
        "                        fitness_list.append(fitness)\n",
        "\n",
        "                        test_fitness = self._evaluate_model(self._population[i], test_dataloader, progr_bar, f\"{message}, evaluating test: \")\n",
        "                        test_fitness_list.append(test_fitness)\n",
        "\n",
        "                    fitness_scores.append(fitness)\n",
        "                    self._training_history[\"train_losses\"][i].append(train_losses_list)\n",
        "                    self._training_history[\"val_metric\"][i].append(fitness_list)\n",
        "                    self._training_history[\"test_metric\"][i].append(test_fitness_list)\n",
        "\n",
        "                if cycle < cycles - 1 or last_cycle_evolution:\n",
        "                  ranked = sorted(list(zip(fitness_scores[:self._genetic_population_size], list(range(self._genetic_population_size)))), key=lambda x: x[0], reverse=True)\n",
        "\n",
        "                  survivors_count = math.ceil(self._genetic_population_size * survivor_fraction)\n",
        "\n",
        "                  for _, index in ranked[survivors_count:]:\n",
        "                      index_a, index_b = random.sample(range(survivors_count), 2)\n",
        "                      self._training_history[\"crossover_history\"][index].append((cycle, index_a, index_b))\n",
        "\n",
        "                      self._population[index] = self._crossover(self._population[index_a], self._population[index_b], mutation_chance)\n",
        "                      self._optimizers[index] = self._reset_optimizer(self._optimizers[index], self._population[index])\n",
        "\n",
        "        return self._training_history\n",
        "\n",
        "    def _crossover(self, model_a: nn.Module, model_b: nn.Module, mutation_chance: float) -> nn.Module:\n",
        "        child = self._model_class(**self._model_params).to(device)\n",
        "        with torch.no_grad():\n",
        "            mods_a = dict(model_a.named_modules())\n",
        "            mods_b = dict(model_b.named_modules())\n",
        "            if self._superviser_population_size and mutation_chance:\n",
        "                mutation_index = random.sample(range(self._superviser_population_size), 1)[0]\n",
        "                mods_mut = dict(self._population[mutation_index].named_modules())\n",
        "\n",
        "            for name, module_child in child.named_modules():\n",
        "\n",
        "                if len(list(module_child.children())) != 0:\n",
        "                    continue\n",
        "\n",
        "                if self._superviser_population_size and  mutation_chance and random.random() < mutation_chance:\n",
        "                    src = mods_mut[name] # type: ignore\n",
        "                elif random.random() < 0.5:\n",
        "                    src = mods_a[name]\n",
        "                else:\n",
        "                    src = mods_b[name]\n",
        "\n",
        "                for param_child, param_src in zip(module_child.parameters(), src.parameters()):\n",
        "                    param_child.data.copy_(param_src.data)\n",
        "\n",
        "                for buf_name, buf_child in module_child.named_buffers():\n",
        "                    buf_src = getattr(src, buf_name)\n",
        "                    buf_child.copy_(buf_src)\n",
        "                    return child\n",
        "        return child\n",
        "\n",
        "    def _train_one_model_one_epoch(self,\n",
        "                                   model: nn.Module,\n",
        "                                   optimizer: optim.Optimizer,\n",
        "                                   criterion: nn.modules.loss._Loss,\n",
        "                                   dataloader: DataLoader,\n",
        "                                   pbar: tqdm|None=None,\n",
        "                                   pbar_message: str|None=None) -> List:\n",
        "\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for i, (inputs, labels) in enumerate(dataloader):\n",
        "            inputs, labels = inputs.to(self._device), labels.to(self._device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "            if pbar:\n",
        "                if pbar_message:\n",
        "                    pbar.set_description(f\"{pbar_message}{i+1}/{len(dataloader)}\")\n",
        "                pbar.update(1)\n",
        "\n",
        "        return train_losses\n",
        "\n",
        "    def _evaluate_model(self, model: nn.Module, dataloader: DataLoader,  pbar: tqdm|None=None, pbar_message: str|None=None) -> float:\n",
        "        model.eval()\n",
        "        scores = []\n",
        "        with torch.no_grad():\n",
        "                for i, (inputs, labels) in enumerate(dataloader):\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    scores.append(self._metric.eval(outputs, labels))\n",
        "                    if pbar:\n",
        "                        if pbar_message:\n",
        "                            pbar.set_description(f\"{pbar_message}{i+1}/{len(dataloader)}\")\n",
        "                        pbar.update(1)\n",
        "        return self._metric.aggregate(scores)\n",
        "\n",
        "    def _reset_optimizer(self, optimizer: optim.Optimizer, model: nn.Module) -> optim.Optimizer:\n",
        "        param_groups = optimizer.param_groups\n",
        "\n",
        "        base_hyperparams = {k: v for k, v in param_groups[0].items() if k != 'params'}\n",
        "\n",
        "        return self._optimizer_class(model.parameters(), **base_hyperparams)\n",
        "\n",
        "    def _layerwise_mse(self, model_a: nn.Module, model_b: nn.Module):\n",
        "        layers_a = [m for m in model_a.modules() if len(list(m.parameters())) > 0]\n",
        "        layers_b = [m for m in model_b.modules() if len(list(m.parameters())) > 0]\n",
        "\n",
        "        mses = []\n",
        "        for la, lb in zip(layers_a, layers_b):\n",
        "            params_a = torch.cat([p.view(-1) for p in la.parameters()])\n",
        "            params_b = torch.cat([p.view(-1) for p in lb.parameters()])\n",
        "            mse = nn.functional.mse_loss(params_a, params_b).item()\n",
        "            mses.append(mse)\n",
        "\n",
        "        return torch.mean(Tensor(mses)).item()\n",
        "\n",
        "    def extract_model(self, smilarity_fraction: float=0.8) -> nn.Module:\n",
        "        mses = [[] for i in range(pop_size)]\n",
        "        for i in range(self._genetic_population_size):\n",
        "          for j in range(i + 1, self._genetic_population_size):\n",
        "            mses[i].append(self._layerwise_mse(self._population[i], self._population[j]))\n",
        "            mses[j].append(self._layerwise_mse(self._population[i], self._population[j]))\n",
        "\n",
        "        row_means = np.mean(mses, axis=1)\n",
        "        selector = row_means <= np.quantile(row_means, smilarity_fraction)\n",
        "\n",
        "        avg_model = self._model_class(**self._model_params).to(device)\n",
        "        avg_state = avg_model.state_dict()\n",
        "\n",
        "        keys = avg_state.keys()\n",
        "        for key in keys:\n",
        "            stacked = torch.stack([self._population[i].state_dict()[key] for i in range(self._genetic_population_size) if selector[i]], dim=0)\n",
        "            avg_state[key] = stacked.mean(dim=0)\n",
        "\n",
        "        avg_model.load_state_dict(avg_state)\n",
        "        return avg_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ccfd18",
      "metadata": {
        "id": "40ccfd18"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.relu(self.conv4(x))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30cd0d56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30cd0d56",
        "outputId": "c2b0b4d7-15d5-490a-9b8d-0f57d67ccbd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:14<00:00, 11.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "base_train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6K0f0dgN2xNV",
      "metadata": {
        "id": "6K0f0dgN2xNV"
      },
      "outputs": [],
      "source": [
        "validation_fraction = 0.2\n",
        "validation_size = int(len(testset) * validation_fraction)\n",
        "seed = 42\n",
        "g = torch.Generator().manual_seed(seed)\n",
        "valset, trainset = torch.utils.data.random_split(base_train_set, [validation_size, len(base_train_set) - validation_size], generator=g)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False, num_workers=num_workers)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                          shuffle=False, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pop_size = 12\n",
        "superviser_pop_size = 4\n",
        "trainer = GeneticTrainer(pop_size, superviser_pop_size, SimpleCNN, optim.Adam, nn.CrossEntropyLoss(), Accuracy(), optimizer_params={\"lr\": 0.001})\n",
        "history = []"
      ],
      "metadata": {
        "id": "GEP-ebfegyFK"
      },
      "id": "GEP-ebfegyFK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7UmHSE9Hq-Ry"
      },
      "id": "7UmHSE9Hq-Ry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b4e3305",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b4e3305",
        "outputId": "3298506a-ada6-4cee-d19c-1b104a641011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ],
      "source": [
        "history.append(trainer.train(16, train_loader, test_loader, val_loader, verbose=1))\n",
        "history.append(trainer.train(16, train_loader, test_loader, val_loader, epoches_per_cycle=2, last_cycle_evolution=False, verbose=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa128407",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa128407",
        "outputId": "1f68911d-7519-443e-b258-12073b95ba8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8273437507450581, 0.8349609375, 0.84033203125, 0.8353515639901161, 0.8313476555049419, 0.833984375, 0.8312500007450581, 0.8319335952401161, 0.8389648459851742, 0.8357421867549419, 0.8348632827401161, 0.8352539055049419]\n",
            "0.84033203125\n",
            "====\n",
            "[0.8121044303797469, 0.8102254746835443, 0.807753164556962, 0.8079509493670886, 0.8095332278481012, 0.8119066455696202, 0.8137856012658228, 0.8097310126582279, 0.8071598101265823, 0.8126977848101266, 0.8122033227848101, 0.8072587025316456]\n",
            "0.807753164556962\n"
          ]
        }
      ],
      "source": [
        "max_vals = [0 for _ in range(pop_size)]\n",
        "test_vals = [0 for _ in range(pop_size)]\n",
        "for i in range(pop_size):\n",
        "    for el in history[-1][\"val_metric\"][i]:\n",
        "        for val in el:\n",
        "            if val > max_vals[i]:\n",
        "                max_vals[i] = val\n",
        "                test_vals[i] = history[-1][\"test_metric\"][i][-1][-1]\n",
        "\n",
        "print(max_vals)\n",
        "print(max(max_vals))\n",
        "\n",
        "print(\"====\")\n",
        "print(test_vals)\n",
        "print(test_vals[np.argmax(max_vals)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = trainer.extract_model(0.8)\n",
        "trainer._evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeWUVIoBAvQz",
        "outputId": "4dc0f6ab-98d5-49b7-d929-966519672611"
      },
      "id": "NeWUVIoBAvQz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.821993670886076"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(trainer._genetic_population_size):\n",
        "  torch.save(trainer._population[i], f\"/content/drive/MyDrive/gen_algo/4l/gen/model_4l_gen_{i}\")"
      ],
      "metadata": {
        "id": "V6sa54lHI9kq"
      },
      "id": "V6sa54lHI9kq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(trainer._genetic_population_size):\n",
        "  trainer._population[i] = torch.load(f\"/content/drive/MyDrive/gen_algo/4l/gen/model_4l_gen_{i}\", weights_only=False)\n",
        "\n",
        "for i in range(trainer._superviser_population_size):\n",
        "  trainer._population[trainer._genetic_population_size + i] = torch.load(f\"/content/drive/MyDrive/gen_algo/4l/sep/model_4l_sep_{i}\", weights_only=False)"
      ],
      "metadata": {
        "id": "ApE_jROLrLCW"
      },
      "id": "ApE_jROLrLCW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pops = []\n",
        "for i in range(trainer._genetic_population_size):\n",
        "  model = trainer._population[i]\n",
        "  pops.append(model)"
      ],
      "metadata": {
        "id": "vKYUyxresDAX"
      },
      "id": "vKYUyxresDAX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(trainer._genetic_population_size):\n",
        "  index_a, index_b = random.sample(range(len(pops)), 2)\n",
        "  trainer._population[i] = trainer._crossover(pops[index_a], pops[index_b], mutation_chance=0.3)"
      ],
      "metadata": {
        "id": "_xC54NxYrfwk"
      },
      "id": "_xC54NxYrfwk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = [[],[]]\n",
        "h[0] = trainer.train(4, train_loader, test_loader, val_loader, epoches_per_cycle=1, last_cycle_evolution=False, mutation_chance=0.4)\n",
        "h[1] = trainer.train(4, train_loader, test_loader, val_loader, epoches_per_cycle=1, last_cycle_evolution=False, mutation_chance=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6IDSuelsHAn",
        "outputId": "5788f77e-4684-4121-a17b-6e5d8da93cdc"
      },
      "id": "u6IDSuelsHAn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = trainer.extract_model(1)\n",
        "trainer._evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDeVc9RDz7hj",
        "outputId": "e6594940-c37c-42c3-cbf6-0257036a3178"
      },
      "id": "GDeVc9RDz7hj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8269382911392406"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = trainer.extract_model(1)\n",
        "trainer._evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_tAeC9nsSaB",
        "outputId": "24b3e444-3cd2-4e37-bfae-7a023e756320"
      },
      "id": "K_tAeC9nsSaB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8267405063291139"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2 = GeneticTrainer(1, 0, SimpleCNN, optim.Adam, nn.CrossEntropyLoss(), Accuracy(), optimizer_params={\"lr\": 0.001})\n",
        "hh = trainer2.train(1, train_loader, test_loader, val_loader, epoches_per_cycle=200, last_cycle_evolution=False, mutation_chance=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dssMXId350w5",
        "outputId": "615deaa0-fadb-4f99-daaf-c8a8388290e8"
      },
      "id": "dssMXId350w5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(hh[\"val_metric\"][0][0]), np.argmax(hh[\"val_metric\"][0][0]), hh[\"test_metric\"][0][0][np.argmax(hh[\"val_metric\"][0][0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZLQQVDV6Imy",
        "outputId": "fb111d06-9338-4f55-e972-01c52e55f28b"
      },
      "id": "gZLQQVDV6Imy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8433593772351742 195 0.8214003164556962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[h[1][\"test_metric\"][i][-1] for i in range(len(h[1][\"test_metric\"]))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQfdSzF3zA_b",
        "outputId": "bf74ecf6-1472-4476-8034-1feafc7d4d90"
      },
      "id": "MQfdSzF3zA_b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.8163568037974683],\n",
              " [0.8149723101265823],\n",
              " [0.8134889240506329],\n",
              " [0.811807753164557],\n",
              " [0.8158623417721519],\n",
              " [0.8145767405063291],\n",
              " [0.8084454113924051],\n",
              " [0.8166534810126582],\n",
              " [0.8089398734177216],\n",
              " [0.8143789556962026],\n",
              " [0.8137856012658228],\n",
              " [0.8194224683544303],\n",
              " [0.8082476265822784],\n",
              " [0.8157634493670886],\n",
              " [0.807060917721519],\n",
              " [0.806368670886076]]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(trainer2._genetic_population_size):\n",
        "  torch.save(trainer2._population[i], f\"/content/drive/MyDrive/gen_algo/4l/sep/model_4l_sep_{i}\")"
      ],
      "metadata": {
        "id": "pjovM3kIJN1z"
      },
      "id": "pjovM3kIJN1z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(trainer2._genetic_population_size):\n",
        "  trainer2._population[i] = torch.load(f\"/content/drive/MyDrive/gen_algo/4l/sep/model_4l_sep_{i}\", weights_only=False)"
      ],
      "metadata": {
        "id": "bnAplMrnrWCy"
      },
      "id": "bnAplMrnrWCy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxwgTek7JgQT",
        "outputId": "31f00f10-6119-4c58-ab35-d77fa9ceff45"
      },
      "id": "FxwgTek7JgQT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"/content/drive/MyDrive/gen_algo/4l/gen\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/gen_algo/4l/sep\", exist_ok=True)"
      ],
      "metadata": {
        "id": "TDmgu8lBJlF5"
      },
      "id": "TDmgu8lBJlF5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}